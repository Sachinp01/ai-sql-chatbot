# AI-Powered SQL Chatbot Backend

An AI-powered chatbot that allows users to ask natural language questions and receive accurate, context-aware answers derived strictly from structured database data.

This project demonstrates a complete **Text-to-SQL AI pipeline** with strong emphasis on **data correctness, security, and explainability**.

---

## ğŸš€ Features

- Natural language â†’ SQL query generation
- Grounded responses strictly from database data (no hallucination)
- Secure SQL validation (prevents injections & unsafe queries)
- Semantic mapping for business terms (e.g., â€œapprovedâ€ loans)
- FastAPI backend with interactive Swagger UI
- PostgreSQL relational database
- Extensible, production-style architecture

---

## ğŸ§  Example

**User Question**
How many loans are approved?


**Generated SQL**
```sql
SELECT COUNT(*) 
FROM loans 
WHERE loan_status IN ('Accepted', 'Complete')
Response

count: 16
ğŸ—ï¸ Architecture Overview
User Question
   â†“
Semantic Mapping (business terms)
   â†“
LLM (Groq â€“ LLaMA 3.1)
   â†“
SQL Normalization & Validation
   â†“
PostgreSQL Execution
   â†“
Human-readable Response
ğŸ§° Tech Stack
Backend: FastAPI

Database: PostgreSQL

LLM: Groq (LLaMA 3.1 â€“ API-based)

ORM: SQLAlchemy

Data Processing: Pandas

Validation: Pydantic

API Docs: Swagger (OpenAPI)

ğŸ“‚ Project Structure
ai_chatbot_backend/
â”‚
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ ai/
â”‚   â”‚   â”œâ”€â”€ sql_generator.py
â”‚   â”‚   â”œâ”€â”€ sql_validator.py
â”‚   â”‚   â”œâ”€â”€ semantic_mapper.py
â”‚   â”‚   â”œâ”€â”€ query_executor.py
â”‚   â”‚   â””â”€â”€ response_formatter.py
â”‚   â”‚
â”‚   â”œâ”€â”€ db/
â”‚   â”‚   â”œâ”€â”€ database.py
â”‚   â”‚   â”œâ”€â”€ models.py
â”‚   â”‚   â””â”€â”€ schemas.py
â”‚   â”‚
â”‚   â”œâ”€â”€ metadata/
â”‚   â”‚   â””â”€â”€ schema_metadata.json
â”‚   â”‚
â”‚   â””â”€â”€ main.py
â”‚
â”œâ”€â”€ data/
â”‚   â””â”€â”€ Sample Data.xlsx
â”‚
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ .env.example
â””â”€â”€ README.md
ğŸ—„ï¸ Data Model
loans table
Column	Description
id	Primary key
user_id	User identifier
loan_status	Status of loan (Accepted, Complete, Rejected, etc.)
net_approved_amount	Approved amount
loan_disbursement_date	Disbursement date
created_at	Record creation time
Semantic Mapping
Business terms are mapped to database values:

Business Term	DB Values
approved	Accepted, Complete
rejected	Rejected
active	Active, InProcess
âš™ï¸ Setup Instructions
1ï¸âƒ£ Clone Repository
git clone <private-repo-url>
cd ai_chatbot_backend
2ï¸âƒ£ Create Virtual Environment
python -m venv venv
source venv/Scripts/activate
3ï¸âƒ£ Install Dependencies
pip install -r requirements.txt
4ï¸âƒ£ Configure Environment Variables
Create .env file:

GROQ_API_KEY=your_groq_api_key
GROQ_MODEL=llama-3.1-8b-instant
â–¶ï¸ Run the Application
uvicorn app.main:app --reload
Open Swagger UI:

http://127.0.0.1:8000/docs
ğŸ”’ Accuracy & Safety
SQL execution is read-only

No multi-statement queries allowed

SQL keywords validated

LLM output normalized before execution

Business semantics handled deterministically

ğŸ“Œ Assignment Coverage Checklist
âœ” Chatbot creation (NL â†’ DB answers)
âœ” Data migration to relational DB
âœ” AI workflow design (Text-to-SQL)
âœ” Schema & metadata documentation
âœ” Accuracy & reliability guarantees
âœ” Aggregations, filters, conditions
âœ” Extensible for joins & follow-up queries

ğŸ“ˆ Future Enhancements (Optional)
Conversation memory for follow-up questions

SQL explanation in responses

ER diagram visualization

Dockerized deployment

Unit & integration tests

ğŸ‘¤ Author
Sachin Patil

This project was built as part of an AI Backend Engineering assignment to demonstrate real-world application of LLMs with structured data systems.

